import pymongo
from IPython.display import Markdown
from embeddings import SentenceTransformerEmbedding, EmbeddingConfig
from sentence_transformers.util import cos_sim
import traceback

class RAG:
    def __init__(self, 
                 mongodbUri: str,
                 dbName: str,
                 dbCollection: str,
                 llm,
                 embeddingName: str = 'keepitreal/vietnamese-sbert'):
        self.client = pymongo.MongoClient(mongodbUri)
        self.db = self.client[dbName]
        self.collection = self.db[dbCollection]
        self.embedding_model = SentenceTransformerEmbedding(
            EmbeddingConfig(name=embeddingName)
        )
        self.llm = llm

    def get_embedding(self, text):
        if not text.strip():
            return []
        try:
            embedding = self.embedding_model.encode(text)
            return embedding.tolist()
        except Exception as e:
            print(f"‚ùå Error generating embedding: {e}")
            return []

    def vector_search(self, user_query: str, limit=5, topic=None):
        """
        Vector search using cosine similarity (manual method for Free Tier)
        """
        query_embedding = self.get_embedding(user_query)
        if not query_embedding:
            return []

        # Get all documents with embedding
        filter_query = {"embedding": {"$exists": True, "$type": "array"}}
        if topic:
            filter_query["topic"] = topic
        docs = list(self.collection.find(filter_query))

        # Calculate cosine similarity
        scored = []
        for doc in docs:
            score = cos_sim([query_embedding], [doc["embedding"]])[0][0].item()
            doc["score"] = score
            scored.append(doc)

        top_docs = sorted(scored, key=lambda d: d["score"], reverse=True)[:limit]
        for doc in top_docs:
            doc.pop("embedding", None)
        return top_docs

    def enhance_prompt(self, user_query: str):
        search_results = self.vector_search(user_query, limit=5)
        context = ""
        if isinstance(search_results, str):
            context = search_results
        else:
            for i, item in enumerate(search_results, 1):
                title = item.get('title', 'N/A')
                price = item.get('current_price', 'Li√™n h·ªá')
                promotions = str(item.get('product_promotion', '')).strip() or 'Kh√¥ng c√≥'
                colors = ', '.join(item.get('color_options', [])) if isinstance(item.get('color_options'), list) else 'Kh√¥ng c√≥'
                specs = item.get('product_specs', '').replace("<br>", "; ") if isinstance(item.get('product_specs'), str) else 'Kh√¥ng c√≥'
                url = item.get('url', '')

                context += f"### {i}. **{title}**\n"
                context += f"- #### **Gi√°**: {price}\n"
                context += f"- #### **∆Øu ƒë√£i**: {promotions}\n"
                context += f"- #### **M√†u s·∫Øc**: {colors}\n"
                context += f"- #### **Th√¥ng s·ªë**: {specs}\n"
                if url:
                    context += f"- *[Xem chi ti·∫øt s·∫£n ph·∫©m]({url})*\n"
                context += "\n"

        final_prompt = f"""B·∫°n l√† m·ªôt chuy√™n gia t∆∞ v·∫•n b√°n ƒëi·ªán tho·∫°i t·∫°i c·ª≠a h√†ng **DBIZ**.

**C√¢u h·ªèi c·ªßa kh√°ch h√†ng:** _{user_query}_

D∆∞·ªõi ƒë√¢y l√† chi ti·∫øt s·∫£n ph·∫©m:

{context}
Vui l√≤ng tr·∫£ l·ªùi kh√°ch m·ªôt c√°ch th√¢n thi·ªán, d·ªÖ hi·ªÉu v√† r√µ r√†ng!  
N·∫øu kh√°ch h√†ng mu·ªën bi·∫øt th√™m, h√£y m·ªùi h·ªç b·∫•m v√†o link ƒë·ªÉ xem chi ti·∫øt s·∫£n ph·∫©m.
"""
        return final_prompt

    def run(self, query, topic=None):
        try:
            print(f"üß† [run()] Query: {query}")
            if topic:
                print(f"üß† [run()] Topic: {topic}")

            query_embedding = self.get_embedding(query)
            if not query_embedding:
                print("‚ö†Ô∏è [run()] Failed to generate query embedding.")
                return "‚ùå Kh√¥ng th·ªÉ t·∫°o embedding cho c√¢u h·ªèi."

            print(f"üß† [run()] Embedding OK, length: {len(query_embedding)}")

            search_results = self.vector_search(query, limit=10, topic=topic)
            print(f"üß† [run()] Retrieved {len(search_results)} results")

            context = "\n\n".join([
                f"{doc['content']} (Ngu·ªìn: {doc.get('url', 'kh√¥ng r√µ')})"
                for doc in search_results if "content" in doc
            ])
            if not context:
                print("‚ö†Ô∏è [run()] No relevant documents found.")
                context = "Kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p trong c∆° s·ªü d·ªØ li·ªáu."
                
            print("===================================================== {Start Data from Db} ========================================")
            print(context)
            print("===================================================== {End Data from Db} ========================================")
            print("===================================================== {Start Truy·ªÅn d·ªØ li·ªáu l√™n LLM t·ª´ Prompt v√† Data tr√™n DB} ========================================")
            prompt = f"""Kh√°ch h·ªèi: \"{query}\"\n\nD∆∞·ªõi ƒë√¢y l√† m·ªôt s·ªë th√¥ng tin li√™n quan:\n\n{context}\n\nTr·∫£ l·ªùi m·ªôt c√°ch t·ª± nhi√™n v√† chi ti·∫øt."""
            print(prompt)
            print("===================================================== {End Truy·ªÅn d·ªØ li·ªáu l√™n LLM t·ª´ Prompt v√† Data tr√™n DB} ========================================")
            return prompt

        except Exception as e:
            print("‚ùå [run()] Exception occurred:", e)
            traceback.print_exc()
            return f"‚ùå L·ªói khi th·ª±c hi·ªán t√¨m ki·∫øm vector: {str(e)}"
